# Raft 协议

## Leader 选举

## 日志复制

## 网络分区


## 日志压缩及快照
创建快照文件时，会将整个节点的状态进行序列化，然后写入稳定的持久化存储。

多个快照文件存在的意义？如果旧的日志已经被压缩，应该只有最新的快照才能恢复完整数据

## linearizablity(线性一致性)语义
客户端对于每个请求都产生一个唯一的序列号，然后 由服务端为每个客户端维护一个 Session， 并对每个请求进行去重。当服务端接收到一个请求时， 会检测其序列号，如果该请求 己经被执行过了，那么就立即返回结果，而不会重新执行。

## 只读请求
1. 网络分区后，少数派节点读请求，请求失败
etcd 默认使用 ReadIndex 机制来实现线性一致性读。当 etcd 节点处理读请求时，节点必须先向 leader 查询 commitIndex，少数派无法联系 leader，导致读取失败。如果开启非线性一致性读请求，则读请求不会失败。

非线性一致性读开启方式：
- SDK 访问需要配置 WithSerializable 选项（默认并不开启）
- etcdctl 访问需要配置 --consistency=s 选项

2. 网络分区后，旧的 leader 节点处于少数派，读取请求到旧 leader 节点，读取失败
leader 节点处理只读请求前，必须检查集群是否存在最新的 Leader 节点。Raft 协议中，通过让 Leader 节点在处理只读请求之前，先和集群中的半数以上的节点交换一次心跳消息来解决这个问题。如果该 Leader 节点可以与集群中半数以上的节点交换一次心跳，则表示该 Leader 节点依然为该集群最新的 Leader 节点 。这样， readlndex 值也就是整个集群中所有节点所能看到的最大提交位置（ commitlndex ） 。

3. 网络分区后，新的 leader 节点处理读请求
TODO
Leader 节点必须有关于己提交日志的最新信息，虽然在节点刚刚赢得选举成为 Leader 时 ，拥有所有己经被提交的日志记录，但是在其任期刚开始时，它可能不知道哪些是己经被提交的日志。为了明确这些信息，它会在其任期开始时提交一条空日志记录，这样上一个任期中的所有日志都会被提交。
Leader 节点会记录该只读请求对应的编号作为 readlndex，当 Leader 节点的提交位置(commitlnd巳x ） 达到或是超过该位置之后， 即 可响应该只读请求。

## ReadIndex
基本原理：Leader节点在处理读请求时，首先需要与集群多数节点确认自己依然是Leader，然后读取已经被应用到应用状态机的最新数据。

基本原理包含两方面：
- Leader首先通过某种机制确认自己依然是Leader；
- Leader需要给客户端返回最近已应用的数据：即最新被应用到状态机的数据。




## PreVote 状态
Raft 协议为了优化无意义的选举，给节点添加了一个 PreVote 的状态：当某个节点要发起选举之前，需要先进入 PreVote 的状态。在 PreVot巳状态下的节点会先尝试连接集群中的其他节点，如果能够成功连接到半数以上的节点，才能真正切换成 Candidate 状态并发起新一轮的选举。

# etcd-raft 模块

## Config 结构体
